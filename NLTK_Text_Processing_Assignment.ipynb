{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ed78fb",
   "metadata": {},
   "source": [
    "# **Language-Specific & Advanced Text Processing Techniques with NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac679cbc",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "In this notebook, we'll use the NLTK library to implement language-specific and advanced text preprocessing techniques.\n",
    "We'll focus on:\n",
    "- **Arabic-specific text processing**: Normalization and diacritics handling.\n",
    "- **English-specific text processing**: Stemming and abbreviation handling.\n",
    "- **Advanced processing**: Tokenization and stopword removal for multilingual text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24028a74",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16166d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdulrahman_1114\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdulrahman_1114\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57023b77",
   "metadata": {},
   "source": [
    "## **2. Load and Explore Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd59b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Text: \n",
      "    \"التكنولوجيا الحديثة تُسهم في تطوير المجتمع.\",\n",
      "    \"اللغة العربية غنية ومليئة بالتحديات.\",\n",
      "    \"قِراءةُ الكُتُبِ تُعزّزُ الثّقافةَ والفهمَ.\",\n",
      "    \"هَلْ يُمكنُكَ أنْ تُساعدني في هذا المشروع؟\",\n",
      "    \"التعليمُ هو المفتاحُ لتحقيقِ الأحلام.\"\n",
      "\n",
      "English Text: \n",
      "    \"Artificial Intelligence is fascinating and powerful.\",\n",
      "    \"He's working on a project related to NLP and data science.\",\n",
      "    \"Can you believe how quickly technology evolves?\",\n",
      "    \"I'm excited to explore the world of programming and coding.\",\n",
      "    \"Learning is a never-ending journey; stay curious!\"\n",
      "\n",
      "Multilingual Text: \n",
      "    \"I enjoy studying الرياضيات because it's challenging.\",\n",
      "    \"Learning البرمجة is fun and rewarding!\",\n",
      "    \"القراءة helps to expand your knowledge and vocabulary.\",\n",
      "    \"The world of الذكاء الاصطناعي is growing rapidly.\",\n",
      "    \"I’m building a مشروع using Python and Arabic text.\",\n",
      "    \"التكنولوجيا الحديثة تساعد في تحسين حياتنا اليومية بشكل كبير.\",\n",
      "    \"Programming in Python is ممتع وسهل التعلم.\",\n",
      "    \"أنا أحب تعلم لغات جديدة مثل الفرنسية والإسبانية alongside Arabic.\",\n",
      "    \"The concept of الوقت in physics is fascinating and intriguing.\",\n",
      "    \"تعلم المهارات الجديدة يساعدك في تحسين مستقبلك الشخصي والمهني.\",\n",
      "    \"AI systems like ChatGPT تساعد في الإجابة عن الأسئلة وتقديم الدعم للمستخدمين.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample Arabic and English text for preprocessing\n",
    "arabic_text = '''\n",
    "    \"التكنولوجيا الحديثة تُسهم في تطوير المجتمع.\",\n",
    "    \"اللغة العربية غنية ومليئة بالتحديات.\",\n",
    "    \"قِراءةُ الكُتُبِ تُعزّزُ الثّقافةَ والفهمَ.\",\n",
    "    \"هَلْ يُمكنُكَ أنْ تُساعدني في هذا المشروع؟\",\n",
    "    \"التعليمُ هو المفتاحُ لتحقيقِ الأحلام.\"\n",
    "'''\n",
    "\n",
    "english_text = '''\n",
    "    \"Artificial Intelligence is fascinating and powerful.\",\n",
    "    \"He's working on a project related to NLP and data science.\",\n",
    "    \"Can you believe how quickly technology evolves?\",\n",
    "    \"I'm excited to explore the world of programming and coding.\",\n",
    "    \"Learning is a never-ending journey; stay curious!\"\n",
    "'''\n",
    "\n",
    "multilingual_text = '''\n",
    "    \"I enjoy studying الرياضيات because it's challenging.\",\n",
    "    \"Learning البرمجة is fun and rewarding!\",\n",
    "    \"القراءة helps to expand your knowledge and vocabulary.\",\n",
    "    \"The world of الذكاء الاصطناعي is growing rapidly.\",\n",
    "    \"I’m building a مشروع using Python and Arabic text.\",\n",
    "    \"التكنولوجيا الحديثة تساعد في تحسين حياتنا اليومية بشكل كبير.\",\n",
    "    \"Programming in Python is ممتع وسهل التعلم.\",\n",
    "    \"أنا أحب تعلم لغات جديدة مثل الفرنسية والإسبانية alongside Arabic.\",\n",
    "    \"The concept of الوقت in physics is fascinating and intriguing.\",\n",
    "    \"تعلم المهارات الجديدة يساعدك في تحسين مستقبلك الشخصي والمهني.\",\n",
    "    \"AI systems like ChatGPT تساعد في الإجابة عن الأسئلة وتقديم الدعم للمستخدمين.\"\n",
    "'''\n",
    "\n",
    "print(\"Arabic Text:\", arabic_text)\n",
    "print(\"English Text:\", english_text)\n",
    "print(\"Multilingual Text:\", multilingual_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36abdf6",
   "metadata": {},
   "source": [
    "## **3. Arabic-Specific Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb10260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Arabic Text:     التكنولوجيا الحديثة تسهم في تطوير المجتمع    اللغة العربية غنية ومليئة بالتحديات    قراءة الكتب تعزّز الثّقافة والفهم    هل يمكنك أن تساعدني في هذا المشروع؟    التعليم هو المفتاح لتحقيق الأحلام\n"
     ]
    }
   ],
   "source": [
    "# Normalize Arabic text \n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(r'[^؀-ۿ ]', '', text)  # Keep only Arabic letters\n",
    "    text = re.sub(r'[ًٌٍَُِْ]', '', text)  # Remove diacritics\n",
    "    return text\n",
    "\n",
    "normalized_arabic = normalize_arabic(arabic_text)\n",
    "print(\"Normalized Arabic Text:\", normalized_arabic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093492d",
   "metadata": {},
   "source": [
    "## **4. English-Specific Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0717aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: \n",
      "    \"Artificial Intelligence is fascinating and powerful.\",\n",
      "    \"He's working on a project related to NLP and data science.\",\n",
      "    \"Can you believe how quickly technology evolves?\",\n",
      "    \"I'm excited to explore the world of programming and coding.\",\n",
      "    \"Learning is a never-ending journey; stay curious!\"\n",
      "\n",
      "\n",
      "      \n",
      "      \n",
      "Expanded Abbreviations: \n",
      "    \"Artificial Intelligence is fascinating and powerful.\",\n",
      "    \"He's working on a project related to NLP and data science.\",\n",
      "    \"Can you believe how quickly technology evolves?\",\n",
      "    \"I am excited to explore the world of programming and coding.\",\n",
      "    \"Learning is a never-ending journey; stay curious!\"\n",
      "\n",
      "\n",
      "      \n",
      "      \n",
      "Tokenized Text: ['``', 'Artificial', 'Intelligence', 'is', 'fascinating', 'and', 'powerful', '.', '``', ',', '``', 'He', \"'s\", 'working', 'on', 'a', 'project', 'related', 'to', 'NLP', 'and', 'data', 'science', '.', '``', ',', '``', 'Can', 'you', 'believe', 'how', 'quickly', 'technology', 'evolves', '?', '``', ',', '``', 'I', 'am', 'excited', 'to', 'explore', 'the', 'world', 'of', 'programming', 'and', 'coding', '.', '``', ',', '``', 'Learning', 'is', 'a', 'never-ending', 'journey', ';', 'stay', 'curious', '!', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Filtered Tokens (no stopwords): ['``', 'Artificial', 'Intelligence', 'fascinating', 'powerful', '.', '``', ',', '``', \"'s\", 'working', 'project', 'related', 'NLP', 'data', 'science', '.', '``', ',', '``', 'believe', 'quickly', 'technology', 'evolves', '?', '``', ',', '``', 'excited', 'explore', 'world', 'programming', 'coding', '.', '``', ',', '``', 'Learning', 'never-ending', 'journey', ';', 'stay', 'curious', '!', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Stemmed Tokens: ['``', 'artifici', 'intellig', 'fascin', 'power', '.', '``', ',', '``', \"'s\", 'work', 'project', 'relat', 'nlp', 'data', 'scienc', '.', '``', ',', '``', 'believ', 'quickli', 'technolog', 'evolv', '?', '``', ',', '``', 'excit', 'explor', 'world', 'program', 'code', '.', '``', ',', '``', 'learn', 'never-end', 'journey', ';', 'stay', 'curiou', '!', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Cleaned Tokens (no punctuation): ['artifici', 'intellig', 'fascin', 'power', 'work', 'project', 'relat', 'nlp', 'data', 'scienc', 'believ', 'quickli', 'technolog', 'evolv', 'excit', 'explor', 'world', 'program', 'code', 'learn', 'journey', 'stay', 'curiou']\n",
      "\n",
      "      \n",
      "      \n",
      "Processed Text: artifici intellig fascin power work project relat nlp data scienc believ quickli technolog evolv excit explor world program code learn journey stay curiou\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and Stem English text\n",
    "\n",
    "abbreviation_mapping = {\"I'm\": \"I am\", \"it's\": \"it is\"}\n",
    "expanded_text = re.sub(r\"\\b(?:I'm|it's)\\b\", lambda match: abbreviation_mapping[match.group(0)], english_text)\n",
    "tokens = word_tokenize(expanded_text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "cleaned_tokens = [token for token in stemmed_tokens if token.isalnum()]\n",
    "processed_text = ' '.join(cleaned_tokens)\n",
    "\n",
    "\n",
    "print(\"Original Text:\", english_text)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Expanded Abbreviations:\", expanded_text)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Tokenized Text:\", tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Filtered Tokens (no stopwords):\", filtered_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Cleaned Tokens (no punctuation):\", cleaned_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Processed Text:\", processed_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe58f5c",
   "metadata": {},
   "source": [
    "## **5. Advanced Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c4d3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['``', 'I', 'enjoy', 'studying', 'الرياضيات', 'because', 'it', \"'s\", 'challenging', '.', '``', ',', '``', 'Learning', 'البرمجة', 'is', 'fun', 'and', 'rewarding', '!', '``', ',', '``', 'القراءة', 'helps', 'to', 'expand', 'your', 'knowledge', 'and', 'vocabulary', '.', '``', ',', '``', 'The', 'world', 'of', 'الذكاء', 'الاصطناعي', 'is', 'growing', 'rapidly', '.', '``', ',', '``', 'I', '’', 'm', 'building', 'a', 'مشروع', 'using', 'Python', 'and', 'Arabic', 'text', '.', '``', ',', '``', 'التكنولوجيا', 'الحديثة', 'تساعد', 'في', 'تحسين', 'حياتنا', 'اليومية', 'بشكل', 'كبير', '.', '``', ',', '``', 'Programming', 'in', 'Python', 'is', 'ممتع', 'وسهل', 'التعلم', '.', '``', ',', '``', 'أنا', 'أحب', 'تعلم', 'لغات', 'جديدة', 'مثل', 'الفرنسية', 'والإسبانية', 'alongside', 'Arabic', '.', '``', ',', '``', 'The', 'concept', 'of', 'الوقت', 'in', 'physics', 'is', 'fascinating', 'and', 'intriguing', '.', '``', ',', '``', 'تعلم', 'المهارات', 'الجديدة', 'يساعدك', 'في', 'تحسين', 'مستقبلك', 'الشخصي', 'والمهني', '.', '``', ',', '``', 'AI', 'systems', 'like', 'ChatGPT', 'تساعد', 'في', 'الإجابة', 'عن', 'الأسئلة', 'وتقديم', 'الدعم', 'للمستخدمين', '.', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Filtered Tokens (no stopwords): ['``', 'enjoy', 'studying', 'الرياضيات', \"'s\", 'challenging', '.', '``', ',', '``', 'Learning', 'البرمجة', 'fun', 'rewarding', '!', '``', ',', '``', 'القراءة', 'helps', 'expand', 'knowledge', 'vocabulary', '.', '``', ',', '``', 'world', 'الذكاء', 'الاصطناعي', 'growing', 'rapidly', '.', '``', ',', '``', '’', 'building', 'مشروع', 'using', 'Python', 'Arabic', 'text', '.', '``', ',', '``', 'التكنولوجيا', 'الحديثة', 'تساعد', 'في', 'تحسين', 'حياتنا', 'اليومية', 'بشكل', 'كبير', '.', '``', ',', '``', 'Programming', 'Python', 'ممتع', 'وسهل', 'التعلم', '.', '``', ',', '``', 'أنا', 'أحب', 'تعلم', 'لغات', 'جديدة', 'مثل', 'الفرنسية', 'والإسبانية', 'alongside', 'Arabic', '.', '``', ',', '``', 'concept', 'الوقت', 'physics', 'fascinating', 'intriguing', '.', '``', ',', '``', 'تعلم', 'المهارات', 'الجديدة', 'يساعدك', 'في', 'تحسين', 'مستقبلك', 'الشخصي', 'والمهني', '.', '``', ',', '``', 'AI', 'systems', 'like', 'ChatGPT', 'تساعد', 'في', 'الإجابة', 'عن', 'الأسئلة', 'وتقديم', 'الدعم', 'للمستخدمين', '.', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Stemmed Tokens: ['``', 'enjoy', 'studi', 'الرياضيات', \"'s\", 'challeng', '.', '``', ',', '``', 'learn', 'البرمجة', 'fun', 'reward', '!', '``', ',', '``', 'القراءة', 'help', 'expand', 'knowledg', 'vocabulari', '.', '``', ',', '``', 'world', 'الذكاء', 'الاصطناعي', 'grow', 'rapidli', '.', '``', ',', '``', '’', 'build', 'مشروع', 'use', 'python', 'arab', 'text', '.', '``', ',', '``', 'التكنولوجيا', 'الحديثة', 'تساعد', 'في', 'تحسين', 'حياتنا', 'اليومية', 'بشكل', 'كبير', '.', '``', ',', '``', 'program', 'python', 'ممتع', 'وسهل', 'التعلم', '.', '``', ',', '``', 'أنا', 'أحب', 'تعلم', 'لغات', 'جديدة', 'مثل', 'الفرنسية', 'والإسبانية', 'alongsid', 'arab', '.', '``', ',', '``', 'concept', 'الوقت', 'physic', 'fascin', 'intrigu', '.', '``', ',', '``', 'تعلم', 'المهارات', 'الجديدة', 'يساعدك', 'في', 'تحسين', 'مستقبلك', 'الشخصي', 'والمهني', '.', '``', ',', '``', 'ai', 'system', 'like', 'chatgpt', 'تساعد', 'في', 'الإجابة', 'عن', 'الأسئلة', 'وتقديم', 'الدعم', 'للمستخدمين', '.', \"''\"]\n",
      "\n",
      "      \n",
      "      \n",
      "Cleaned Tokens (no punctuation): ['enjoy', 'studi', 'الرياضيات', 'challeng', 'learn', 'البرمجة', 'fun', 'reward', 'القراءة', 'help', 'expand', 'knowledg', 'vocabulari', 'world', 'الذكاء', 'الاصطناعي', 'grow', 'rapidli', 'build', 'مشروع', 'use', 'python', 'arab', 'text', 'التكنولوجيا', 'الحديثة', 'تساعد', 'في', 'تحسين', 'حياتنا', 'اليومية', 'بشكل', 'كبير', 'program', 'python', 'ممتع', 'وسهل', 'التعلم', 'أنا', 'أحب', 'تعلم', 'لغات', 'جديدة', 'مثل', 'الفرنسية', 'والإسبانية', 'alongsid', 'arab', 'concept', 'الوقت', 'physic', 'fascin', 'intrigu', 'تعلم', 'المهارات', 'الجديدة', 'يساعدك', 'في', 'تحسين', 'مستقبلك', 'الشخصي', 'والمهني', 'ai', 'system', 'like', 'chatgpt', 'تساعد', 'في', 'الإجابة', 'عن', 'الأسئلة', 'وتقديم', 'الدعم', 'للمستخدمين']\n",
      "\n",
      "      \n",
      "      \n",
      "Processed Text: enjoy studi الرياضيات challeng learn البرمجة fun reward القراءة help expand knowledg vocabulari world الذكاء الاصطناعي grow rapidli build مشروع use python arab text التكنولوجيا الحديثة تساعد في تحسين حياتنا اليومية بشكل كبير program python ممتع وسهل التعلم أنا أحب تعلم لغات جديدة مثل الفرنسية والإسبانية alongsid arab concept الوقت physic fascin intrigu تعلم المهارات الجديدة يساعدك في تحسين مستقبلك الشخصي والمهني ai system like chatgpt تساعد في الإجابة عن الأسئلة وتقديم الدعم للمستخدمين\n"
     ]
    }
   ],
   "source": [
    "# Tokenize multilingual text and remove stopwords\n",
    "\n",
    "tokens_multi = word_tokenize(multilingual_text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in tokens_multi if token.lower() not in stop_words]\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(token) for token in filtered_tokens]\n",
    "cleaned_tokens = [token for token in stemmed_tokens if token.isalnum()]\n",
    "processed_text = ' '.join(cleaned_tokens)\n",
    "\n",
    "print(\"Original Tokens:\", tokens_multi)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Filtered Tokens (no stopwords):\", filtered_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Stemmed Tokens:\", stemmed_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Cleaned Tokens (no punctuation):\", cleaned_tokens)\n",
    "print(\"\"\"\n",
    "      \n",
    "      \"\"\")\n",
    "print(\"Processed Text:\", processed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74647084",
   "metadata": {},
   "source": [
    "## **6. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c15de",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "- We used NLTK for tokenization, stemming, and stopword removal.\n",
    "- Arabic-specific text was normalized by removing diacritics and non-Arabic characters.\n",
    "- English-specific preprocessing included stemming and abbreviation handling.\n",
    "\n",
    "### Challenges:\n",
    "- NLTK doesn't have built-in support for advanced Arabic preprocessing, so custom functions were used.\n",
    "- Handling mixed-language text requires careful tokenization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
